# Deep Learning Foundations

A list of the papers introducing the most popular advancement in deep learning. A list that is curated to only present the essentials, the hit singles of deep learning as we know it if you will. I decided not to include any advanced papers as I consider that they are of little use for beginners and practionners with no interest in advanced research.
These are the papers that I consider paramount to read and understand as they present the challenges they tried to tackle and as a result gives some insight into neural networks practical uses.


## Architectures

#### Feed forward networks

#### Convolutional neural networks


#### Generative Adversarial Networks
**Generative adversarial nets** Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014) [[pdf]](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)


## Activation Functions

#### Relu
**Deep sparse rectifier neural networks**, Glorot Xavier, Antoine Bordes, and Yoshua Bengio (2011) [[pdf]](http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf)

#### LeakyRelu
**Rectifier Nonlinearities Improve Neural Network Acoustic Models**  Andrew L. Maas Awni Y. Hannun Andrew Y. Ng (2012) [[pdf]](https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)

#### PRelu
**Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification** Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun (2015) [[pdf]](https://arxiv.org/pdf/1502.01852.pdf)

#### ELU
**Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)**, Djork-Arné Clevert, Thomas Unterthiner, Sepp Hochreiter (2016) [[pdf]](https://arxiv.org/pdf/1511.07289).

### Review
**An overview of gradient descent optimization algorithms**, Sebastian Ruder (2016) [[pdf]](https://arxiv.org/pdf/1609.04747.pdf).



## Gradient Descent

#### Best practices
**Efficient Backprop** LeCun, Yann A., Léon Bottou, Genevieve B. Orr, and Klaus-Robert Müller (2012) [[pdf]](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)

#### Adam
**Adam: A Method for Stochastic Optimization**, Diederik P. Kingma, Jimmy Ba (2014) [[pdf]](http://arxiv.org/abs/1412.6980)

#### Follow the regularized leader
**Ad Click Prediction: a View from the Trenches**, H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica (2013) [[pdf]](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf)

#### Xavier initialisation

**Understanding the difficulty of training deep feedforward neural networks**  Xavier Glorot, Yoshua Bengio (2010) [[pdf]](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)


#### He et al. initialisation

**Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification** Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun (2015) [[pdf]](https://arxiv.org/pdf/1502.01852.pdf)


## Regularization

**Dropout: A Simple Way to Prevent Neural Networks from Overfitting**, Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky
Ilya Sutskever, Ruslan Salakhutdinov (2014) [[pdf]](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf).

**Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**, Sergey Ioffe, Christian Szegedy (2015) [[pdf]](https://arxiv.org/pdf/1502.03167).

**Overtraining, regularization, and searching for minimum in neural networks**, Sjöberg Jonas, Lennart Ljung (1992) [[pdf]](https://pdfs.semanticscholar.org/6bb2/8b64d262b6aefae157be03399db08e41307c.pdf)


## Architectures

#### AlexNet

**ImageNet classification with deep convolutional neural networks**, Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. In Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1 (2012) [[pdf]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).

#### VGGNet

**Very deep convolutional networks for large-scale image recognition**, K Simonyan, A Zisserman - arXiv preprint arXiv:1409.1556, (2014) [[pdf]](https://arxiv.org/pdf/1409.1556v6.pdf).


#### Google LeNet

**Going deeper with convolutions**, Szegedy, Christian, et al., Proceedings of the IEEE conference on computer vision and pattern recognition. (2015) [[pdf]](https://arxiv.org/pdf/1409.4842.pdf).


#### Inception V3
